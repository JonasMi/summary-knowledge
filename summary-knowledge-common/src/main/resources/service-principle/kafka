kafka is a distributed partitioned replicated commit logservice

kafka对消息的保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为consumer,此外
kafka集群有多个kafka实例组成，每个实例成为broker,无论是kafka集群，还是producer和consumer都
依赖于zookeeper来保证系统可用性，集群保存一些meta信息。

Topic:一个topic认为是一类消息，每个topic将被分成多个partition(区),每个partition在存储层面都是
append log文件。任何发布到此partition的消息都会 被追加到log文件的尾部,每条消息在文件中的位置称为offset
通过分区，可以将日志内容分散到多个server上，来避免文件尺寸达到单机磁盘的上线。
此外越多的partitions意味着可以容纳更多的consumer，有效的提升并发消费能力。

distribution:一个topic多个partitions,将被分布在多个server上，每个server负责partitions中的消息读写操作。
每个partitions需要备份的个数replicas,每个partition将会被备份到多台机器上，以提高可用性

Producers:producer将消息发布到指定的topic中，同时producer也能决定将消息归属于哪个partition;比如基于
round-robin 方式或者通过其他的一些算法等

consumers:本质上kafka只支持topic,每个consumer属于一个consumer group,反过来说，每个group中可以有多个
consumer,发送到topic的消息，只会被订阅此topic的每个group中的一个consumer消费

如果所有的consumer都具有相同的group，这种情况和queue模式很像，消息将会在consumers之间负载均衡

如果所有的sonsumer都具有不同的group,消息会广播给所有的消费者。

 kafka的设计原理决定,对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息.
 
 需要考虑的影响性能点很多,除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.
 kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,
 批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.
 对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,
 socket直接读取相应的内存区域即可,而无需进程再次copy和交换. 
 其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;
 压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.
 kafka支持gzip/snappy等多种压缩方式.
 
 负载均衡: producer将会和Topic下所有partition leader保持socket连接;
 消息由producer直接通过socket发送到broker,中间不会经过任何"路由层".事实上,
 消息被路由到哪个partition上,有producer客户端决定.比如可以采用"random""key-hash""轮询"等,
 如果一个topic中有多个partitions,那么在producer端实现"消息均衡分发"是必要的.
 
 consumer端向broker发送"fetch"请求,并告知其获取消息的offset;
 此后consumer将会获得一定条数的消息;consumer端也可以重置offset来重新消费消息.
 
  5、消息传送机制
    对于JMS实现,消息传输担保非常直接:有且只有一次(exactly once).在kafka中稍有不同:
    1) at most once: 最多一次,这个和JMS中"非持久化"消息类似.发送一次,无论成败,将不会重发.
    2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.
    3) exactly once: 消息只会发送一次.
    at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,
    导致部分消息未能继续处理.那么此后"未处理"的消息将不能被fetch到,这就是"at most once".
    at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,
    这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是"at least once"，原因offset没有及时的提交给zookeeper，
    zookeeper恢复正常还是之前offset状态.
    exactly once: kafka中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.
    通常情况下"at-least-once"是我们搜选.(相比at most once而言,重复接收数据总比丢失数据要好).
 
 
 6、复制备份
    kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower
    (可以没有);备份的个数可以通过broker配置文件来设定.leader处理所有的read-write请求,
    follower需要和leader保持同步.Follower和consumer一样,消费消息并保存在本地日志中;
    leader负责跟踪所有的follower状态,如果follower"落后"太多或者失效,leader将会把它从replicas同步列表中删除.
    当所有的follower都将一条消息保存成功,此消息才被认为是"committed",那么此时consumer才能消费它.
    即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收,只要zookeeper集群存活即可.
    (不同于其他分布式存储,比如hbase需要"多数派"存活才行)
    当leader失效时,需在followers中选取出新的leader,可能此时follower落后于leader,
    因此需要选择一个"up-to-date"的follower.选择follower时需要兼顾一个问题,
    就是新leaderserver上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,
    意味着此server将承受着更多的IO压力.在选举新leader,需要考虑到"负载均衡".
 
 8、分配
    kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)
    1) Broker node registry: 当一个kafkabroker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.
    格式: /broker/ids/[0...N]   -->host:port;其中[0..N]表示broker id,每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),znode的值为此broker的host:port信息.
    2) Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.
    格式: /broker/topics/[topic]/[0...N]  其中[0..N]表示partition索引号.
    3) Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了"负载均衡".
    一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,
    让partition相对均衡的分散到每个consumer上.
    4) Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.
    格式:/consumers/[group_id]/ids/[consumer_id]
    仍然是一个临时的znode,此节点的值为{"topic_name":#streams...},即表示此consumer目前所消费的topic + partitions列表.
    5) Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.
    格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]-->offset_value
    此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.
    6) Partition Owner registry: 用来标记partition被哪个consumer消费.临时znode
    格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]-->consumer_node_id当consumer启动时,所触发的操作:
    A) 首先进行"Consumer id Registry";
    B) 然后在"Consumer id Registry"节点下注册一个watch用来监听当前group中其他consumer的"leave"和"join";只要此znode path下节点列表变更,
    都会触发此group下consumer的负载均衡.
    (比如一个consumer失效,那么其他consumer接管partitions).
    C) 在"Broker id registry"节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.
 
 
 
